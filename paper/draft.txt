New ideas: 
    - how to find good parameters for GA? 
    - how to prove GA will guess the right bangs consistently (randomness)? 
    - what is the right heuristics: wall clock or gc time?

Intro
 Problem:
  lazy functional languages & slow performance because of 
laziness
    -> bangs to the rescue
  but,
    non-experts are not able to write correct strictness 
annotations
    library writers can put in annotations for some usage but 
not all
  Solution:
    machine learning to evolve best performing annotation 
combination
      why we use GA
    benefits:
      infers good annotations for non-expert programmers
      customized to particular application (not one-size fits 
all)
      take annotations of library writers as hints
    drawbacks:
      may introduce non-termination or other semantic changes
        non-terminating genes won't survive
        use analysis to make sure all introduced bangs are 
executed during GA.
        static analysis/demand analysis of call graph
        todo: is this sufficient? can we find an example where 
things go awry
        changes to side effects
          users should inspect resulting program as a sanity 
check
      takes a long time to run (quantify)
        isn't part of development compilation cycle
        okay if it runs overnight, better than the alternative
        can tune times based on GA parameters
      useless bangs survive evolution
        complicates understanding program
        todo: be smarter about not adding useless bangs
              try pruning bangs
      not robust on all possible data sets
         although possible to construct examples with this 
property
         not common in practice
         todo: show not common in practice
   Evaluation:
     benchmark set is interesting and representative and as 
large as we can do
       different application areas (aeson, nathan, #?)
       different programs using the same libraries (2-aseon, 
1-nathan, #)
       different input data sources  (#)
     compare performance of
        no annotations, expert annotations, inferred 
annotations
     inferred annotations are faster in most cases
     robustness of inferred annotations for single program 
over multiple datasets

2. Background: what GA are, what strictness annotation are
    Two important ways strictness can affect performance: unneccessary 
    annotation wastes computation; uneccessary laziness causes space leak and
    increases GC work. 

3.  To demonstrate out use of Genetic Algorithm to infer strictness annotations,
    we describe a programmer's workflow using our optimizer. 
#TODO# talk about representation and explain

## Configuration

#TODO# A configuration file looks like this, and explain. 

    Depending on properties of the bare program and the desired performance, the
    programmer need to provide a set of parameters as an aid to the optimizer. 
    They include the standard parameters to GA: crossover rate, crossover 
    parameter, mutation rate, mutation parameter, inital mutation parameter, 
    population and maximum number of generation. Besides listed above, the 
    programmer can also specify the number of iterations for each fitness run. 
    We will discuss each parameter in following sections as they come into 
    effect. 

## The First Generation
#TODO talk about starting point: naked v.s. expert program#
    After carefully picking the parameters, the programmer passes the orginal 
    Haskell source, annotated or not, to the optimizer. The optimizer then 
    reads from the source its strictness strategy and generates the 
    corresponding gene. Then the optimizer populates the initial generation
    with that gene and its mutations, using the initial mutate paremeter. Since
    the inital mutate parameter is interpreted as the probability of mutation
    that happens to each gene, a higher value will result in a diverse
    generation whereas a lower value will produce genes more closely resemble
    the original one. Therefore when a programmer is confident with the current
    strictness strategy, they can choose a lower value to help preserve the
    strategy, and a higher value otherwise to explore more space. Besides the
    initial mutate parameter, the population also affects the performance of
    the optimizer. A larger population will guarantee better coverage of the
    search space, whereas a smaller one reduces the cost of each generation. 

## Measuring Fitness
    After a generation of genes are prepared, we measure each gene's fitness by
    profiling the Haskell program it represents. Such profiles contain
    various performance information that can be used to calculate fitness
    scores, and the decision of which to use depends on the most critical
    feature of performance that the programmer desires. If shrinking memory
    footprint is on the top of the agenda, one can assign a higher score to the
    gene which represents a program that requires less allocation. For example,
    to use the reciprocal or negation of allocation as fitness score. If
    runtime is of priority, one can score by the reciprocal of runtime to let
    faster genes stand out. In the case where both memory usage and runtime
    need improvement, GC time serves as a good choice since it correlates to
    both heuristics. 
    During the measurement stage, we must keep in mind that introducing
    strictness annotations may change the program semantics and introduce
    non-termination. Therefore we timeout program runs if they take much longer
    than the initial program. With this strategy, we can always avoid programs
    that don't terminate on provided inputs, but not on all. We will discuss
    soundness in later sections with mroe details. 

## Reproducing New Generations
    The Genetic Algorithm handles reproduction of the next generations,
    provided a mutation function and a crossover function. We take the mutation
    rate as the percentage of genes we wish to get by mutation for the next
    generate, whereas the crossover rate stands for the percentage of genes in
    the next generation that come from crossover. 

    We mutate each gene by flipping any bit with a probability equal to the 
    mutation parameter. 
    Notice that the mutation parameter discussed here differs from the 
    initial mutation parameter, which controls the diversity of the first 
    generation. Here the mutation parameter decides the rate of progress in 
    each generation: the higher it is, the more significantly the genes change.
    Just like the initial mutation parameter, the mutation parameter eventually
    affects the performance of the optimizer. When each new generation changes
    greatly from the previous one, the optimizer has the chance of converging
    more quickly; whereas when the progress is small and careful, the converged
    result can be more accurate. 

    In crossover we pick half of the bits
    for a new gene randomly from the corresponding positions in one parent, 
    while taking the rest from the other parent. Such strategy will make
    stronger genes more likely to survive: when a newly added annotation 
    improves performance, its improvement is likely to persist regardless of
    other annotations. There are less common cases where an annotation improves
    performance on its own, but must be rid of in an optimal program. In that
    situation, the correct combinition of annotations can be discovered by
    future mutations that takes off the harmful bit. #TODO waving hands here#

    #TODO# DISCUSS EACH CASE OF BANG BENEFIT IN DETAIL

3. Our use of GAs to infer strictness annotations represents a certain
    strictness strategy #define# as a gene #define#, and their performance
    as the fitness score #define#. Since any Haskell program has fixed
    strictness points #better term?#, and adding or removing strictness
    annotations do not change this space, we can use a bit vector of fixed
    length to encode the program's strictness strategy. #example on a small 
    program?# 
    
    In choosing a proper heuristic as the fitness score there are
    several options: to use the program runtime, allocation, GC time or a 
    combination of them. #todo more on this?# This choice depends on how the
    programmer wishes the program to perform, and the most critical heuristic
    should be chosen as the score#if there are several important ones?#. 
    #Should we give some advice on picking the fitness, and how?#

    Besides the choice of the fitness score, there are a few other parameters
    available to the programmer to fine-tune the genetic algorithm: population, 
    generation, mutation rate and crossover rate. A good combination of the 
    parameters can contribute to the productivity of genetic algorithm. 
    #todo translate into English: #
    - larger generation number and population covers more space but increases
      the runtime of optimizer. 
    - larger mutation and crossover rate searches more space, but might miss 
      strictness points #is this true?# 
    #TODO support by data/research in machine learning#
    #TODO do we still want to change parameters over time?#

    The workflow of our optimizer, after setting the above parameters, is as 
    follows: the programmer will feed the initial program source, annotated or
    not, as a starting point for the genetic algorithm. Existing annotations
    serve as hints to the optimizer, and if the mutation rate is low #move to
    previous seciton?#, the hints will likely survive if they contribute to 
    performance. Then we populate an initial generation with a gene representing
    the initial program and its mutations. Based on this initial generation, we
    calculate the fitness score of each gene from the performance of the program
    it represents, pick out the stronger ones among them to generate the next 
    generation #better term?#, and repeat the process. 

    Advantages: not linear to search space #evidence?#, once discovered faster 
    programs won't get any worse

    key issue: how fast a generation can be run
       what have we done to make this run fast?
        make search space as small as possible
        parallelize the benchmarking process

    key issue: picking good values for parameters
       how does running time vary with #genes, #generations
    key issue: preserving semantics
        ??

4. Preserving Semantics
    ???

5. Evaluation
    Sanity check:
     In small cases, we find right bangs.
    Benchmarks: what they are
      todo: more benchmarks
    Evaluation:
       performance naked, expert, inferred
        on as many programs as possible.
       stability across data sets
    Running time of inference as parameters and program size 
change.

6. Related Work
    see earlier email
7. Future work and conclusions

things we'd like to be able to do
 1. guarantee not to change semantics (termination or side 
effects)
 2. minimal bang additions
 3. learn the pattern of good strictness annotations from multiple programs. 
